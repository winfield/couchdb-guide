## 高性能 ##

本章会教会你如何用最快的方式插入数据到CouchDB以及如何以最快的方法来查询数据. 同时也将解释为什么使用不同的技术会产生不同的性能.

先简单描述下本章节的内容: 批量操作可以使用更低的开销, 得到更大的处理能力和更好的空间效率. 如果在应用里不能使用批量模式, 我们也描述了其他可以得到较好处理能力和空间效率的选项. 最后, 我们会描述如何使用Erlang来直接和CouchDB交互, 如果你想要把CouchDB整合到一个非HTTP协议的服务器, 像是SMTP(email)或者XMPP(chat), 这将会是个非常有用的技术.

### 要做好性能测试不是件容易的事 ###

每个应用程序都是不同的. 对于性能的要求不总是那么明显. 不同的情况需要使用不同的参数. 一个经典的取舍例子就是延时和处理能力. 并发能力是另外一个因素. 许多数据库平台在处理100个并发客户端时和处理1000个或更多的并发客户端时, 做法有很大的不同. 有些数据需要进行串行化处理, 这就会增加响应客户端的总时间(延时), 以及服务器的负载. 我们认为简单的数据结构和读取模式, 可以使得应用程序在可缓存性和可扩展性方面作出很大的不同, 这点我们晚点再来介绍.

结果是: 真正的性能测试需要真实的环境. 模拟一个环境是很困难的. Erlang在强负载下会表现的更好(特别是在多核的环境里), 所以我们经常会看到一些测试并不能给予CouchDB足够大的负载使其真正达到极限.

让我们来看一个典型的web应用. Craigslist并非真是这样运作的(因为我们也并不知道Craigslist是如何运作的), 但是对于展示性能测试的问题, 这已经足够接近了.

你有一个web服务器, 某个中间件, 以及一个数据库. 当一个用户请求进来时, web数据库处理网络和解析HTTP请求. 请求接着被转交给中间件, 它会找出哪个服务需要运行, 然后启动这个服务来处理请求. 中间件可能会和你的数据库以及其他的一些外部资源像是文件或者远程web服务打交道. 最后请求返回至web服务器, 它会发出结果的HTML. 这个HTML会包含存在于web服务器的其他资源的链接(像是CSS, JS, 或者图片文件). 每次的请求都会执行这一过程. 虽然每次都会稍有不同, 但是一般来讲, 所有的请求都是类似的. 并且在此过程中, 会有一些缓存来保存中间结果以避免重复计算的昂贵代价.

这里有很多动态的部分. 从上往下, 对所有的组件进行评估来找出瓶颈在哪是非常复杂的(但是能找出来当然是好的). 所以我们开始编造数据. 绝对的值并不重要; 只有它们相互之间的关系才是重要的. 比如说, 一个请求需要1.5秒(1,500毫秒)才能完全的返回给浏览器.

在像Craigslist这样简单的例子里, 会有初始的HTML, 一个CSS文件, 一个JS文件, 以及一个favicon. 除了HTML, 这些都是静态资源, 它们需要从硬盘(或者内存)中读取出来, 然后返回给浏览器并生成它们. 对于性能来说, 最值得做的事情就是保持数据尽可能的小(GZIP压缩, 高压缩率的JPG), 并且避免同时请求它们(浏览器HTTP层面的缓存). 让web服务器变得更快, 我们并不是很关心(是的, 这很好, 但是这里我们并不想关注于这些静态资源) 让我们假设所有的静态资源都需要500毫秒来处理和生成.

到Steve Souders, web性能优化大师那里去阅读所有的关于如何合理使用HTTP来改进性能的方法吧. 他写的YSlow对于网站优化来说是必不可少的工具.

生成初始HTML需要占用我们1000毫秒. 网络延时(请查看第一章, 为什么使用CouchDB?)也会花掉我们200毫秒. 再让我们假设HTTP解析, 中间件处理路由和运行, 以及访问数据库都会占用相同的时间, 每样200毫秒.

如果你现在开始优化你的web应用, 然后在数据库层得到了一个10ms的访问时间, 那么这也许并不是一个很快的速度(除非你有其他数据证明它已经算是不错了).

然而, 把一个单一的请求这样进行分块, 并且一个个的来看每个组件要花费多少时间, 这同样是一种误导. 即便在正常的负载下, 只有一小部分的时间是花费在数据库上的, 这也并不能告诉你在流量峰值时会发生什么. 如果所有的请求都涌向同一个数据库, 那么任何的锁行为都会堵塞大量的web请求. 在正常负载时, 你的数据库可能只占用了总时间的一小部分, 但是在流量高峰时, 它可能就会变成一个瓶颈, 进而影响整个应用服务器在峰值时的运行. CouchDB可以最小化这种影响, 通过为每一个连接都配备一个Erlang进程, 来保证所有的客户端都可以得到处理, 而只会增加一点点的延时.

### 高性能的CouchDB ###

现在你知道了数据库性能只是整个web应用性能的一个小部分, 我们会给你一些小提示来处理CouchDB的大多数性能问题.

CouchDB从头到尾就是被设计用于高并发的环境的, 这是大多数web应用所面临的情况. 然而, 有时间, 我们需要导入一大块的数据到CouchDB或者要把另一个数据库的数据完全的转移过来. 又或者我们要构建一个自定义的Erlang应用, 它需要从更底层连接CouchDB, 而不是通过HTTP.

#### 硬件 ####

通常人们会想要知道他们应该使用的什么类型的硬件, 内存多大, 什么样的CPU型号等等. 真正的答案是, CouchDB足够灵活, 它可以跑在任何硬件上, 从智能手机到集群. 所以答案多种多样. 

更多的内存会更好, 因为CouchDB大量的使用了文件系统的缓存. CPU的核心数对于创建视图比处理文档更加重要. 固态硬盘(SSD)很棒, 因为在载入老的卷时, 它们可以用最小的开销把数据附加到文件. 当它们变得越来越快, 越来越便宜时, 对于CouchDB来说, 将会变得方便.

#### 一个关于实现的注意事项 ####

我们不会再在这里长篇大论的讨论B-tree, 但是理解CouchDB的数据格式是了解哪种策略可以得到最佳性能的关键. 每次有更新时, CouchDB会从磁盘里读取指向更新文档的B-tree节点或者是一个key的范围, 里面可以找到新文档的_id.

这种读取通常可以从文件系统缓存里得到, 除非被更新的文档处于一个很长时间都没有被读取的区域里. 在这些情况下, 就必须要到磁盘里查找了, 这会阻塞写入并且还有其他的一些连锁反应. 防止此类的磁盘查找就是CouchDB性能优化要做的事.

在本章中, 我们会使用JavaSciprt测试套件里拿来的数字. 虽然它不是最准确的, 但是它使用的策略(记录在10内可以被保存的文档的数量)不坏. 用于性能测试的硬件并不是很高端: 只是一个老型号的白色的Intel Core 2 Duo的Macbook(还记得这个型号吗?).

在CouchDB运行在5984端口上时, 你可以在CouchDB源代码目录的bench目录下, 通过运行./runner.sh来进行性能测试.

### 批量插入和单调的文档ID ###

批量插入是不需要进行查找就能写入的最佳方式. 在文件大到不能被缓存时, 随机的ID就会被迫进行查找. 随机ID也大型文件准备的, 因为在一个大型的数据库里, 一个B-tree的叶子节点里很少会包含多个文档.

#### 一个优化的例子: 视图和复制 ####

如果你对如何对CouchDB进行性能优化好奇, 可以看看视图和复制是怎么做的. 一个复制被触发后, 为了最小化磁盘查找, 会大批量的把更新发送到目标数据库. 目前源代码仓库中的0.11.0开发版中, 视图的生成速度比0.10版本快了3-5倍.

视图会从磁盘上载入一堆更新, 把它们传入视图引擎, 然后再把视图记录写出来. 每一块的数据都包含了几百个文档, 所以就可以利用我们将在下面一节将会看到的批量操作的高效性.

### 批量文档插入 ###

通过HTTP, 最快的将数据导入CouchDB的模式是_bulk_docs. 批量文档API可以在一个POST请求中接受一个文档的集合, 并在一个索引操作里把它们全部存储进CouchDB里.

在使用一种脚本语言导入一组数据时应该使用批量文档API. 这样可以比单独的更新快10到100倍, 并且在大多数语言里都很容易实现.

影响批量操作性能的主要因素是更新的大小, 它同时包括总数据的大小以及更新的文档的数量的大小.

下面是四个不同数量级的批量文档插入, 从100个文档, 到1,000个, 5,000个, 10,000个:

				bulk_doc_100
				4400 docs
				437.37574552683895 docs/sec

				bulk_doc_1000
				17000 docs
				1635.4016354016355 docs/sec

				bulk_doc_5000
				30000 docs
				2508.1514923501377 docs/sec

				bulk_doc_10000
				30000 docs
				2699.541078016737 docs/sec

你可以看到更大的批量产生了更好的性能, 在这个测试中最高达到了2700个文档每秒. 对于更大的一些文档, 可能更小些的批量会更些好些. 为了进行参照, 所有的文档看起来都是像这个样子: {"foo":"bar"}

虽然每秒2,700个文件已经很不错了, 我们想要更加强大的! 接下来, 我们要同时运行几个批量文档插入.

使用一个不同的脚本(在同一个目录下, 利用bash和cURL配合benchbulk.sh进行)进行测试, 我们平行的把大批量的文档插入到CouchDB. 每批的数量为1000个文档, 在规定时间里同时平行运行10个, 这样运行10次取平均值, 在MacBook Pro上我们可以看到每秒插入了大约3650个文档. Benchbulk测试脚本同时也使用了连续的ID.

我们看到, 合理使用批量文档模式和连续ID, 只使用脚本语言, 每秒我们就可以插入多于3000个的文档.

### 批量模式 ###

为了避免单一文件写入时的索引和硬盘同步开销, 有一个选项可以使CouchDB在内存中保存批量的文档. 当达到一定界限时, 或者在用户触发时, 再冲刷(flushing)到硬盘上. 批量选项没有普通更新所拥有的数据完整性保证, 所以它只能在某些较近更新的潜在丢失可以被接受时使用.

因为在冲刷发生以前, 批量模式只把更新存储在内存中, 所以如果在保存到CouchDB时出现了错误, 那么这些更新就会丢失. 默认的, CouchDB会每秒一次把内存中的更新冲刷到硬盘, 因此即使有数据丢失, 仍然只是很小的一部分. 为了反映batch=ok模式时数据完整性的减弱, HTTP返回码会变成202 Accepted, 而不是201 Created.

批量模式的理想使用场景是日志类型应用, 那里会有许多分布式的写入, 每一个都会存储不连续的事件到CouchDB中. 在一个普通的日志场景中, 允许罕见的更新丢失, 来换取更大的处理能力是值得的.

使用批量模式进行可靠的数据存储有一个模式. 它和在客户端不知道保存是否成功之前, 需要在多个节点上进行可靠的数据存储时所使用的模式是相同的. 简言之, 应用服务器(或者远程客户端)使用batch=ok在节点A进行存储, 然后观察来自节点B的变更通知, 只有当来自节点B的变更里包含与之前相关的更新时, 才认为这个更新是成功的. 我们在第16章, 复制中更加详细的讲解了这一模式.

				batch_ok_doc_insert
				4851 docs
				485.00299940011996 docs/sec

这一JavaScript基准测试只得到了每秒500个文档的结果, 比批量文档插入API要慢上六倍. 然而, 它的优势在于, 客户端不需要自己创建批量数据.

### 单文档插入 ###

普通web应用的CouchDB使用场景是单文档的插入. 因为每个插入来自不同的客户端, 且需要一整个HTTP请求和响应的开销, 它的写入能力通常来说是最低的.

最慢的插入CouchDB的用法恐怕就是一个客户端的大量串行写入了. 想像下这样一个场景: 每一个写入都信赖于先前一个写入的结果, 只有先前写入成功, 后者才能正常工作. 单听这描述就会觉得这个场景不太好. 如果你发现自己处在了这么个位置, 那么你也许还有其他的问题需要处理.

一个客户端串行进行写入, 每秒可以写入258个文档(大概是最差的写入场景了).

				single_doc_insert
				2584 docs
				257.9357157117189 docs/sec

延时提交(Delayed commit)(和连续的UUID结合使用)可能是CouchDB最重要的性能配置选项了. 当它被设置为true时(这是默认的选项), CouchDB允许每个操作完成后不使用显式的fsync. Fsync操作会占用时间(硬盘可能需要进行查找, 在有些平台上硬盘缓存满了, 等等). 所以要求每个操作后都使用fsync极大的限制了CouchDB非批量(non-bulk)写入的性能.

延时提交应该就按默认的被设置为true, 除非你的环境里要求当收到更新时必须需要知道(比如CouchDB作为一个更大的事务的一部分时). 也可以使用_ensure_full_commit API来触发fsync(比如, 在做完几个操作以后).

当延时提交被禁用时, CouchDB会在响应客户端前, 确实的把数据写到硬盘上(除非是在batch=ok模式下). 这种方式的代码实现其实更加简单, 所以当在处理较大流量时, 它的开销更低. 然而, 对于某个独立的客户端而言, 看起来就会比较慢了. 下面是在完整提交模式下的性能测试结果:

				single_doc_insert
				46 docs
				4.583042741855135 docs/sec

看看吧, 完整提交启用后的单文档插入--每秒只有4到5个文档! 因为Mac OS X有真正的fsync实现, 所以这是100%真实的结果, 感激吧! 不过别担心, 在批量操作时, 完整提交会表现的更好些.

从另一方面来说, 对于大块的数据, 关闭延时提交可以有更好的表现. 这也让我们了解到, 优化一个应用时不按照某本参考书上的做, 总是会得到更好的结果.

### Hovercraft ###

Hovercraft是一个使用Erlang来访问CouchDB的库. Hovercraft基准测试应该会展示出CouchDB硬盘和索引子系统的最快性能表现, 因为它避免了所有的HTTP连接以及JSON转换开销.

Hovercraft主要在是HTTP接口不能满足足够的控制, 或者HTTP接口是多余的时候使用. 举个例子, 在CouchDB上实现Jabber实时消息系统可能会使用ejabberd和Hovercraft. 最简单的创建一个容错消息队列可能会是RabbitMQ和Hovercraft的结合.

Hovercraft是从一个客户端项目里提取出来的, 这个项目使用CouchDB来存储大量的电子邮件, 把它们作为文档的附件. HTTP接口没有一个简单的方法, 可以使得批量数据更新可以带有二进制的附件, 所以我们使用Hovercraft, 把一个Erlang SMTP服务器直接连接到了CouchDB. 这样在保持批量数据更新高效性的同时, 可以直接把附件存储到硬盘上.

Hovercraft包括了一个基础的测试套件, 我们可以通过它得知每秒可以处理多少文档.

				> hovercraft:lightning().
				Inserted 100000 docs in 9.37 seconds with batch size of 1000.
				(10672 docs/sec)

### 取舍 ###

使用工具X可能可以得到5ms的响应时间, 要比市面上其他产品都快一个等级. 编程其实就是一个取舍的过程, 每个人都被约束在这条定律上.

在外界看来, 所有那些不使用工具X的人都像是傻瓜. 但是速度和延时只是一部分. 一个产品的延时从5ms升高到50ms可能没人会察觉出来. 速度可以换取其他的一些东西, 比如:

内存

为了不用一遍一遍的重复计算, 工具X可能会有一个不错的缓存层, 可以把计算结果保存在内存中. 如果你受限于CPU, 那么这样做不错; 但如果受限于内存, 这样做就不大好了. 这是一个取舍的过程.

并发

工具X的智能数据结构在处理一个单一请求时非常的快, 因为它在大多数时候都是这样快, 所以看起来像是它在平行处理多个请求时也会同样的快. 虽然, 最终, 大量的并发请求填满了请求队列, 响应时间变得很长. 另一种情况则可能是工具X在单核或者双核的CPU工作的很好, 但在更多的核的CPU上则不能更好利用起来, 结果另外几个核那样一直空闲在那了.

可靠性

确保数据真正被存储了是一个昂贵的操作. 确保数据保存在一个一致的状态没有损坏也是. 这里有两个需要取舍的地方. 第一个, 在保存到硬盘之前, 使用缓存在内存中存储数据可以保证更高的数据处理能力. 在电源中断或者软硬件崩溃的时候, 这样做就会导致数据丢失. 应用可能接受, 也不可能不能接受这种数据丢失. 第二个, 错误发生后需要进行一致性的检查, 如果你有大量的数据, 这几天要耗费几天的时间. 如果你能承受应用下线, 那这样做没问题, 但很可能你根本承受不了.

要确保了解什么是你需要的, 并且选择那些满足你需要的工具, 而不要只是选择那些有些漂亮数据的工具. 当应用程序为了修复需要下线一天, 而你的客户根本没有耐心等待时, 或者更糟糕的, 数据丢失了时, 谁才是那个傻瓜呢? 

#### 但是...我的老板就是喜欢看那些个破数据! ####

你想要知道哪些数据库, 缓存, 编程语言, 语言框架, 以及工具更快, 更好, 更强壮. 数据会很酷--你可以画出漂亮的图表, 从而通过对比作出选择.

但是, 一个好的执行官首先要知道的事情是, 她所看到的是不充分的数据, 因为根据数字画出的图表和真实情况是有出入的. 而那些没有经过仔细调查得出的图表则根本没有任何价值.

如果你确实需要产生一些数字, 要确保明白结果中体现了多少信息, 哪些信息又不能体现出来. 在上交这些数字以前, 还要确保看的人也懂得这些道理. 当然, 最好的方法还是尽可能模拟真实世界的环境进行测试. 虽然这不是件容易的事情.

#### 一个呼吁 #####

我们所在的市场是数据库市场和key/value存储的市场. 每种解决文案都在数据, 硬件, 安装设置以及操作性上其亮点, 所以你总是能找到一个适合你的问题的选择. 但是如何找出来呢? 理解情况下, 你可以下载安装所有可能的工具, 用适当的测试数据为每一个都进行性能测试, 做压力测试, 然后再对比结果. 这样做很可能要花上几周的时间, 而你可能没有这么多的时间.

我们想要号召存储系统的开发者们, 可以编写一套分析测试套件, 用于模拟系统的各个不同的使用模式(大量的读请求, 大量的写请求, 容错性, 分页式操作, 以及更多的选项). 容错性测试套件应该包含那些恢复数据的步骤, 比如数据重建或者数据检查. 我们想要这些系统的用户来帮助其开发者们找出, 如何才能可靠的比较各个使用场景.

我们开发的是CouchDB, 并且我们很高兴拥有这么一个测试套件! 更好的是, 通过简单的对比, 开发者们对一部分客观性能数据也表示认同. 我们知道这要需要做大量的工作, 而结果可能仍然是令人置疑的, 但是能帮到用户作出合理的选择, 我们很高兴.

